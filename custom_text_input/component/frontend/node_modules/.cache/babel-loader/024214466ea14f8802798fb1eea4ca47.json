{"ast":null,"code":"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.Assistant = exports.ChatStream = void 0;\nconst chat_1 = require(\"./data/chat\");\nconst chatCompletion_1 = require(\"./data/chatCompletion\");\nconst chatStream_1 = require(\"./data/chatStream\");\nconst chatCompletionStream_1 = require(\"./data/chatCompletionStream\");\nconst listFiles_1 = require(\"./data/listFiles\");\nconst describeFile_1 = require(\"./data/describeFile\");\nconst deleteFile_1 = require(\"./data/deleteFile\");\nconst uploadFile_1 = require(\"./data/uploadFile\");\nconst asstDataOperationsProvider_1 = require(\"./data/asstDataOperationsProvider\");\nconst context_1 = require(\"./data/context\");\nvar chatStream_2 = require(\"./chatStream\");\nObject.defineProperty(exports, \"ChatStream\", {\n  enumerable: true,\n  get: function () {\n    return chatStream_2.ChatStream;\n  }\n});\n/**\n * The `Assistant` class holds the data plane methods for interacting with\n *  [Assistants](https://docs.pinecone.io/guides/assistant/understanding-assistant).\n *\n *  This class can be instantiated through a {@link Pinecone} object, and is used to interact with a specific assistant.\n *\n *  @example\n *  ```typescript\n *  import { Pinecone } from '@pinecone-database/pinecone';\n *  const pc = new Pinecone();\n *  const assistant = pc.assistant('assistant-name');\n *  ```\n */\nclass Assistant {\n  /**\n   * Creates an instance of the `Assistant` class.\n   *\n   * @param assistantName - The name of the assistant.\n   * @param config - The Pinecone configuration object containing an API key and other configuration parameters\n   * needed for API calls.\n   *\n   * @throws An error if no assistant name is provided.\n   */\n  constructor(assistantName, config) {\n    if (!assistantName) {\n      throw new Error('No assistant name provided');\n    }\n    this.config = config;\n    const asstDataOperationsProvider = new asstDataOperationsProvider_1.AsstDataOperationsProvider(this.config, assistantName);\n    this.assistantName = assistantName;\n    this._chat = (0, chat_1.chat)(this.assistantName, asstDataOperationsProvider);\n    this._chatStream = (0, chatStream_1.chatStream)(this.assistantName, asstDataOperationsProvider, this.config);\n    this._chatCompletion = (0, chatCompletion_1.chatCompletion)(this.assistantName, asstDataOperationsProvider);\n    this._chatCompletionStream = (0, chatCompletionStream_1.chatCompletionStream)(this.assistantName, asstDataOperationsProvider, this.config);\n    this._listFiles = (0, listFiles_1.listFiles)(this.assistantName, asstDataOperationsProvider);\n    this._describeFile = (0, describeFile_1.describeFile)(this.assistantName, asstDataOperationsProvider);\n    this._uploadFile = (0, uploadFile_1.uploadFile)(this.assistantName, asstDataOperationsProvider, this.config);\n    this._deleteFile = (0, deleteFile_1.deleteFile)(this.assistantName, asstDataOperationsProvider);\n    this._context = (0, context_1.context)(this.assistantName, asstDataOperationsProvider);\n  }\n  // --------- Chat methods ---------\n  /**\n   * Sends a message to the assistant and receives a response. Retries the request if the server fails.\n   *\n   * @example\n   * ```typescript\n   * import { Pinecone } from '@pinecone-database/pinecone';\n   * const pc = new Pinecone();\n   * const assistantName = 'test1';\n   * const assistant = pc.assistant(assistantName);\n   * const chatResp = await assistant.chat({messages: [{role: 'user', content: \"What is the capital of France?\"}]});\n   * // {\n   * //  id: '000000000000000023e7fb015be9d0ad',\n   * //  finishReason: 'stop',\n   * //  message: {\n   * //    role: 'assistant',\n   * //    content: 'The capital of France is Paris.'\n   * //  },\n   * //  model: 'gpt-4o-2024-05-13',\n   * //  citations: [ { position: 209, references: [Array] } ],\n   * //  usage: { promptTokens: 493, completionTokens: 38, totalTokens: 531 }\n   * // }\n   * ```\n   *\n   * @param options - A {@link ChatOptions} object containing the message and optional parameters to send to the\n   * assistant.\n   * @returns A promise that resolves to a {@link ChatModel} object containing the response from the assistant.\n   */\n  chat(options) {\n    return this._chat(options);\n  }\n  /**\n   * Sends a message to the assistant and receives a streamed response as {@link ChatStream<StreamedChatResponse>}. Retries the request if the server fails.\n   *\n   * @example\n   * ```typescript\n   * import { Pinecone } from '@pinecone-database/pinecone';\n   * const pc = new Pinecone();\n   * const assistantName = 'test1';\n   * const assistant = pc.assistant(assistantName);\n   * const chatStream = await assistant.chatStream({ messages: [{ role: 'user', content: 'What is the capital of France?'}]});\n   *\n   * // stream the response and log each chunk\n   * for await (const chunk of newStream) {\n   *   console.log(chunk);\n   * }\n   * // each chunk will have a variable shape depending on the type:\n   * // { type:\"message_start\", id:\"response_id\", model:\"gpt-4o-2024-05-13\", role:\"assistant\"}\n   * // { type:\"content_chunk\", id:\"response_id\", model:\"gpt-4o-2024-05-13\", delta:{ content:\"The\"}}\n   * // { type:\"content_chunk\", id:\"response_id\", model:\"gpt-4o-2024-05-13\", delta:{ content:\" test\"}}\n   * // { type:\"message_end\", id:\"response_id\", model:\"gpt-4o-2024-05-13\", finishReason:\"stop\",usage:{ promptTokens:371,completionTokens:48,totalTokens:419}}\n   * ```\n   *\n   * @param options - A {@link ChatOptions} object containing the message and optional parameters to send to the\n   * assistant.\n   * @returns A promise that resolves to a {@link ChatStream<StreamedChatResponse>}.\n   */\n  chatStream(options) {\n    return this._chatStream(options);\n  }\n  /**\n   * Sends a message to the assistant and receives a response that is compatible with\n   * [OpenAI's Chat Completion API](https://platform.openai.com/docs/guides/text-generation. Retries the request if the server fails.\n   *\n   * @example\n   * ```typescript\n   * import { Pinecone } from '@pinecone-database/pinecone';\n   * const pc = new Pinecone();\n   * const assistantName = 'test1';\n   * const assistant = pc.assistant(assistantName);\n   * const chatCompletion = await assistant.chatCompletion({ messages: [{ role: 'user', content: 'What is the capital of France?' }]});\n   * console.log(chatCompletion);\n   * // {\n   * //  id: \"response_id\",\n   * //  choices: [\n   * //  {\n   * //    finishReason: \"stop\",\n   * //    index: 0,\n   * //    message: {\n   * //      role: \"assistant\",\n   * //      content: \"The data mentioned is described as \\\"some temporary data\\\"  [1].\\n\\nReferences:\\n1. [test-chat.txt](https://storage.googleapis.com/knowledge-prod-files/your_file_resource) \\n\"\n   * //    }\n   * //   }\n   * //  ],\n   * //  model: \"gpt-4o-2024-05-13\",\n   * //  usage: {\n   * //    promptTokens: 371,\n   * //    completionTokens: 19,\n   * //    totalTokens: 390\n   * //  }\n   * // }\n   * ```\n   *\n   * @param options - A {@link ChatCompletionOptions} object containing the message and optional parameters to send\n   * to an assistant.\n   * @returns A promise that resolves to a {@link ChatCompletionModel} object containing the response from the assistant.\n   */\n  chatCompletion(options) {\n    return this._chatCompletion(options);\n  }\n  /**\n   * Sends a message to the assistant and receives a streamed response as {@link ChatStream<StreamedChatCompletionResponse>}. Response is compatible with\n   * [OpenAI's Chat Completion API](https://platform.openai.com/docs/guides/text-generation. Retries the request if the server fails.\n   *\n   * @example\n   * ```typescript\n   * import { Pinecone } from '@pinecone-database/pinecone';\n   * const pc = new Pinecone();\n   * const assistantName = 'test1';\n   * const assistant = pc.assistant(assistantName);\n   * const chatStream = await assistant.chatCompletionStream({messages: [{role: 'user', content: \"What is the capital of France?\"}]});\n   *\n   * // stream the response and log each chunk\n   * for await (const chunk of newStream) {\n   *   if (chunk.choices.length > 0 && chunk.choices[0].delta.content) {\n   *     process.stdout.write(chunk.choices[0].delta.content);\n   *   }\n   * }\n   * // { id: 'response_id', choices: [{ index: 0, delta: { role: 'assistant' }, finishReason: null }], model: 'gpt-4o-2024-05-13', usage: null }\n   * // { id: 'response_id', choices: [{ index: 0, delta: { content: 'The' }}, finishReason: null }], model: 'gpt-4o-2024-05-13', usage: null }\n   * // { id: 'response_id', choices: [{ index: 0, delta: { content: ' test' }}, finishReason: null }], model: 'gpt-4o-2024-05-13', usage: null }\n   * // { id: 'response_id', choices: [], model: 'gpt-4o-2024-05-13', usage: { promptTokens: 371, completionTokens: 48, totalTokens: 419 }}\n   * ```\n   *\n   * @param options - A {@link ChatCompletionOptions} object containing the message and optional parameters to send\n   * to an assistant.\n   * @returns A promise that resolves to a {@link ChatStream<StreamedChatCompletionResponse>}.\n   */\n  chatCompletionStream(options) {\n    return this._chatCompletionStream(options);\n  }\n  // --------- File methods ---------\n  /**\n   * Lists files (with optional filter) uploaded to an assistant.\n   *\n   * @example\n   * ```typescript\n   * import { Pinecone } from '@pinecone-database/pinecone';\n   * const pc = new Pinecone();\n   * const assistantName = 'test1';\n   * const assistant = pc.assistant(assistantName);\n   * const files = await assistant.listFiles({filter: {metadata: {key: 'value'}}});\n   * console.log(files);\n   * // {\n   * //  files: [\n   * //    {\n   * //      name: 'temp-file.txt',\n   * //      id: '1a56ddd0-c6d8-4295-80c0-9bfd6f5cb87b',\n   * //      metadata: undefined,\n   * //      createdOn: 2025-01-06T19:14:21.969Z,\n   * //      updatedOn: 2025-01-06T19:14:36.925Z,\n   * //      status: 'Available',\n   * //      percentDone: 1,\n   * //      signedUrl: undefined,\n   * //      errorMessage: undefined\n   * //    }\n   * //  ]\n   * // }\n   * ```\n   *\n   * @param options - A {@link ListFilesOptions} object containing optional parameters to filter the list of files.\n   * @returns A promise that resolves to a {@link AssistantFilesList} object containing a list of files.\n   */\n  listFiles(options) {\n    if (!options) {\n      options = {};\n    }\n    return this._listFiles(options);\n  }\n  /**\n   * Describes a file uploaded to an assistant.\n   *\n   * @example\n   * ```typescript\n   * import { Pinecone } from '@pinecone-database/pinecone';\n   * const pc = new Pinecone();\n   * const assistantName = 'test1';\n   * const assistant = pc.assistant(assistantName);\n   * const files = await assistant.listFiles();\n   * let fileId: string;\n   * if (files.files) {\n   *     fileId = files.files[0].id;\n   * } else {\n   *     fileId = '';\n   * }\n   * const resp = await assistant.describeFile({fileId: fileId})\n   * console.log(resp);\n   * // {\n   * //  name: 'test-file.txt',\n   * //  id: '1a56ddd0-c6d8-4295-80c0-9bfd6f5cb87b',\n   * //  metadata: undefined,\n   * //  createdOn: 2025-01-06T19:14:21.969Z,\n   * //  updatedOn: 2025-01-06T19:14:36.925Z,\n   * //  status: 'Available',\n   * //  percentDone: 1,\n   * //  signedUrl: undefined,\n   * //   errorMessage: undefined\n   * // }\n   * ```\n   *\n   * @param fileId - The ID of the file to describe.\n   * @param includeUrl - Whether to include the signed URL in the response. Defaults to true.\n   * @returns A promise that resolves to a {@link AssistantFileModel} object containing the file details.\n   */\n  describeFile(fileId) {\n    let includeUrl = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : true;\n    return this._describeFile(fileId, includeUrl);\n  }\n  /**\n   * Uploads a file to an assistant.\n   *\n   * Note: This method does *not* use the generated code from the OpenAPI spec.\n   *\n   * @example\n   * ```typescript\n   * import { Pinecone } from '@pinecone-database/pinecone';\n   * const pc = new Pinecone();\n   * const assistantName = 'test1';\n   * const assistant = pc.assistant(assistantName);\n   * await assistant.uploadFile({path: \"test-file.txt\", metadata: {\"test-key\": \"test-value\"}})\n   * // {\n   * //  name: 'test-file.txt',\n   * //  id: '921ad74c-2421-413a-8c86-fca81ceabc5c',\n   * //  metadata: { 'test-key': 'test-value' },\n   * //  createdOn: Invalid Date,  // Note: these dates resolve in seconds\n   * //  updatedOn: Invalid Date,\n   * //  status: 'Processing',\n   * //  percentDone: null,\n   * //  signedUrl: null,\n   * //  errorMessage: null\n   * // }\n   * ```\n   *\n   * @param options - A {@link UploadFile} object containing the file path and optional metadata.\n   * @returns A promise that resolves to a {@link AssistantFileModel} object containing the file details.\n   */\n  uploadFile(options) {\n    return this._uploadFile(options);\n  }\n  /**\n   * Deletes a file uploaded to an assistant by ID.\n   *\n   * @example\n   * ```typescript\n   * import { Pinecone } from '@pinecone-database/pinecone';\n   * const pc = new Pinecone();\n   * const assistantName = 'test1';\n   * const assistant = pc.assistant(assistantName);\n   * const files = await assistant.listFiles();\n   * let fileId: string;\n   * if (files.files) {\n   *    fileId = files.files[0].id;\n   *    await assistant.deleteFile({fileId: fileId});\n   *  }\n   * ```\n   *\n   * @param options - A {@link DeleteFile} object containing the file ID to delete.\n   * @returns A promise that resolves to void on success.\n   */\n  deleteFile(fileId) {\n    return this._deleteFile(fileId);\n  }\n  /**\n   * Retrieves [the context snippets](https://docs.pinecone.io/guides/assistant/understanding-context-snippets) used\n   * by an assistant during the retrieval process.\n   *\n   * @example\n   * ```typescript\n   * import { Pinecone } from '@pinecone-database/pinecone';\n   * const pc = new Pinecone();\n   * const assistantName = 'test1';\n   * const assistant = pc.assistant(assistantName);\n   * const response = await assistant.context({query: \"What is the capital of France?\"});\n   * console.log(response);\n   * // {\n   * //  snippets: [\n   * //    {\n   * //      type: 'text',\n   * //      content: 'The capital of France is Paris.',\n   * //      score: 0.9978925,\n   * //      reference: [Object]\n   * //    },\n   * //  ],\n   * //  usage: { promptTokens: 527, completionTokens: 0, totalTokens: 527 }\n   * // }\n   * ```\n   *\n   * @param options\n   * @returns A promise that resolves to a {@link Context} object containing the context snippets.\n   */\n  context(options) {\n    return this._context(options);\n  }\n}\nexports.Assistant = Assistant;","map":{"version":3,"mappings":";;;;;;AAAA;AAQA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AA+BA;AAASA;EAAAC;EAAAC;IAAA,8BAAU;EAAA;AAAA;AAEnB;;;;;;;;;;;;;AAaA,MAAaC,SAAS;EAepB;;;;;;;;;EASAC,YAAYC,aAAqB,EAAEC,MAA6B;IAC9D,IAAI,CAACD,aAAa,EAAE;MAClB,MAAM,IAAIE,KAAK,CAAC,4BAA4B,CAAC;;IAE/C,IAAI,CAACD,MAAM,GAAGA,MAAM;IACpB,MAAME,0BAA0B,GAAG,IAAIC,uDAA0B,CAC/D,IAAI,CAACH,MAAM,EACXD,aAAa,CACd;IACD,IAAI,CAACA,aAAa,GAAGA,aAAa;IAElC,IAAI,CAACK,KAAK,GAAG,eAAI,EAAC,IAAI,CAACL,aAAa,EAAEG,0BAA0B,CAAC;IACjE,IAAI,CAACG,WAAW,GAAG,2BAAU,EAC3B,IAAI,CAACN,aAAa,EAClBG,0BAA0B,EAC1B,IAAI,CAACF,MAAM,CACZ;IACD,IAAI,CAACM,eAAe,GAAG,mCAAc,EACnC,IAAI,CAACP,aAAa,EAClBG,0BAA0B,CAC3B;IACD,IAAI,CAACK,qBAAqB,GAAG,+CAAoB,EAC/C,IAAI,CAACR,aAAa,EAClBG,0BAA0B,EAC1B,IAAI,CAACF,MAAM,CACZ;IACD,IAAI,CAACQ,UAAU,GAAG,yBAAS,EAAC,IAAI,CAACT,aAAa,EAAEG,0BAA0B,CAAC;IAC3E,IAAI,CAACO,aAAa,GAAG,+BAAY,EAC/B,IAAI,CAACV,aAAa,EAClBG,0BAA0B,CAC3B;IACD,IAAI,CAACQ,WAAW,GAAG,2BAAU,EAC3B,IAAI,CAACX,aAAa,EAClBG,0BAA0B,EAC1B,IAAI,CAACF,MAAM,CACZ;IACD,IAAI,CAACW,WAAW,GAAG,2BAAU,EAC3B,IAAI,CAACZ,aAAa,EAClBG,0BAA0B,CAC3B;IACD,IAAI,CAACU,QAAQ,GAAG,qBAAO,EAAC,IAAI,CAACb,aAAa,EAAEG,0BAA0B,CAAC;EACzE;EAEA;EAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;EA2BAW,IAAI,CAACC,OAAoB;IACvB,OAAO,IAAI,CAACV,KAAK,CAACU,OAAO,CAAC;EAC5B;EAEA;;;;;;;;;;;;;;;;;;;;;;;;;;EA0BAC,UAAU,CAACD,OAAoB;IAC7B,OAAO,IAAI,CAACT,WAAW,CAACS,OAAO,CAAC;EAClC;EAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;EAqCAE,cAAc,CAACF,OAA8B;IAC3C,OAAO,IAAI,CAACR,eAAe,CAACQ,OAAO,CAAC;EACtC;EAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;EA4BAG,oBAAoB,CAACH,OAA8B;IACjD,OAAO,IAAI,CAACP,qBAAqB,CAACO,OAAO,CAAC;EAC5C;EAEA;EAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;EA+BAI,SAAS,CAACJ,OAA0B;IAClC,IAAI,CAACA,OAAO,EAAE;MACZA,OAAO,GAAG,EAAE;;IAEd,OAAO,IAAI,CAACN,UAAU,CAACM,OAAO,CAAC;EACjC;EAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;EAmCAK,YAAY,CAACC,MAAc,EAA4B;IAAA,IAA1BC,iFAAsB,IAAI;IACrD,OAAO,IAAI,CAACZ,aAAa,CAACW,MAAM,EAAEC,UAAU,CAAC;EAC/C;EAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;EA4BAC,UAAU,CAACR,OAA0B;IACnC,OAAO,IAAI,CAACJ,WAAW,CAACI,OAAO,CAAC;EAClC;EAEA;;;;;;;;;;;;;;;;;;;;EAoBAS,UAAU,CAACH,MAAc;IACvB,OAAO,IAAI,CAACT,WAAW,CAACS,MAAM,CAAC;EACjC;EAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;EA4BAI,OAAO,CAACV,OAAuB;IAC7B,OAAO,IAAI,CAACF,QAAQ,CAACE,OAAO,CAAC;EAC/B;;AAhXFW","names":["Object","enumerable","get","Assistant","constructor","assistantName","config","Error","asstDataOperationsProvider","asstDataOperationsProvider_1","_chat","_chatStream","_chatCompletion","_chatCompletionStream","_listFiles","_describeFile","_uploadFile","_deleteFile","_context","chat","options","chatStream","chatCompletion","chatCompletionStream","listFiles","describeFile","fileId","includeUrl","uploadFile","deleteFile","context","exports"],"sourceRoot":"","sources":["../../src/assistant/index.ts"],"sourcesContent":[null]},"metadata":{},"sourceType":"script"}