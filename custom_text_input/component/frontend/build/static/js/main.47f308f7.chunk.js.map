{"version":3,"sources":["streamlit_copilot.tsx","index.tsx"],"names":["Copilot","StreamlitComponentBase","userTextarea","suggestionTextarea","state","requestsThisMinute","currentMinute","Math","floor","Date","now","totalRequests","successfulRequests","failedRequests","inputCost","outputCost","totalCost","debounceTimer","render","theme","this","props","height_int","args","font_fam","font","f_height","f_focused","primaryColor","f_not_focused","secondaryBackgroundColor","style","fontSize","color","textColor","marginBottom","padding","backgroundColor","borderRadius","border","display","justifyContent","alignItems","toFixed","onClick","resetCounters","cursor","title","tabIndex","height","width","isFocused","overflowY","overflowX","position","onFocus","_onFocus","onBlur","_onBlur","marginLeft","fontFamily","marginTop","whiteSpace","outline","base","value","suggestion","readOnly","ref","textarea","text","onChange","onKeyDown","_onTextAreaBlur","onScroll","forceUpdate","event","target","setState","window","clearTimeout","timer","setTimeout","trim","api_upl","callApi","then","key","preventDefault","prevState","syntheticEvent","textAreaIsFocused","Streamlit","setComponentValue","abortController","AbortController","executeToolCalls","async","results","toolCall","toolCalls","functionName","function","name","JSON","parse","arguments","console","log","toolResult","executeTool","searchQuery","query","enhancedResult","push","toolName","toString","String","pineconeApiKey","pineconeIndexName","openaiApiKey","embeddingResponse","fetch","method","headers","body","stringify","model","input","ok","Error","status","queryEmbedding","json","data","embedding","pineconeHost","indexUrl","includes","searchResponse","vector","topK","includeMetadata","searchData","matches","length","map","match","metadata","content","filter","join","error","makeFollowUpCall","apiUrl","userInput","toolResults","followUpPrompt","prompt_template","api_key","questionText","question_title","model_kwargs","isChatApi","replace","payload","validParams","max_tokens","temperature","top_p","stop","messages","role","stream","prompt","echo","response","signal","responseJson","fullResponse","choices","message","extractedAnswer","answerTagIndex","indexOf","substring","endTagIndex","abort","Promise","resolve","api_url","tools","type","description","parameters","properties","required","tool_choice","errorText","inputTokens","usage","prompt_tokens","outputTokens","completion_tokens","inputPrice","outputPrice","estimatedInputTokens","ceil","newInputCost","newOutputCost","tool_calls","finalResponse","thinkTagIndex","endThinkIndex","componentDidUpdate","scrollTop","componentWillUnmount","withStreamlitConnection","ReactDOM","StrictMode","document","getElementById"],"mappings":"qXAuBA,MAAMA,UAAgBC,IAA+B,cAAD,yBAE1CC,aAA2C,KAAK,KAChDC,mBAAiD,KAAK,KACvDC,MAAQ,CACb,KAAQ,GACR,WAAc,GACd,WAAa,EACb,mBAAqB,EACrBC,mBAAoB,EACpBC,cAAeC,KAAKC,MAAMC,KAAKC,MAAQ,KACvCC,cAAe,EACfC,mBAAoB,EACpBC,eAAgB,EAChBC,UAAW,EACXC,WAAY,EACZC,UAAW,EACXC,cAAe,MAChB,KAEMC,OAAS,KACd,MAAM,MAAEC,GAAUC,KAAKC,MACvB,IAAKF,EACH,OAAO,oFAET,MAAMG,EAAaF,KAAKC,MAAME,KAAa,OACrCC,EAAWL,EAAMM,KAEjBC,EAAWJ,EAAa,KAExBK,EAAY,aAAeR,EAAMS,aACjCC,EAAgB,aAAeV,EAAMW,yBAE3C,OACI,6BAEE,yBAAKC,MAAO,CACVC,SAAU,MACVC,MAAOd,EAAMe,UACbC,aAAc,QACdC,QAAS,QACTC,gBAAiBlB,EAAMkB,gBACvBC,aAAc,QACdC,OAAQ,aAAepB,EAAMW,yBAC7BU,QAAS,OACTC,eAAgB,gBAChBC,WAAY,WAEZ,6BACG,8CAA2B,WAAStB,KAAKhB,MAAMO,cAAa,sBACjDS,KAAKhB,MAAMQ,mBAAkB,qBAC9BQ,KAAKhB,MAAMS,eAAc,0CAEDO,KAAKhB,MAAMC,mBAAkB,MAAKe,KAAKC,MAAME,KAAgB,UAChG,6BACA,yCAAsB,YAAUH,KAAKhB,MAAMU,UAAU6B,QAAQ,GAAE,eAAcvB,KAAKhB,MAAMW,WAAW4B,QAAQ,GAAE,cAAavB,KAAKhB,MAAMY,UAAU2B,QAAQ,IAIzJ,4BACEC,QAASxB,KAAKyB,cACdd,MAAO,CACLC,SAAU,QACVI,QAAS,cACTC,gBAAiBlB,EAAMS,aACvBK,MAAO,QACPM,OAAQ,OACRD,aAAc,QACdQ,OAAQ,WAEVC,MAAM,kBAAgB,uBAM1B,yBACEC,SAAU,EACVjB,MACE,CACEkB,OAAOvB,EACPwB,MAAM,OACNX,OAAOnB,KAAKhB,MAAM+C,UAAYxB,EAAWE,EACzCS,aAAa,QACbc,UAAU,SACVC,UAAU,SACVC,SAAU,WACVjB,gBAAiBlB,EAAMW,0BAG3ByB,QAASnC,KAAKoC,SACdC,OAAQrC,KAAKsC,SAEb,8BACE3B,MACE,CACE4B,WAAW,QACXC,WAAWpC,EACXqC,UAAU,QACVC,WAAY,WACZZ,MAAQ,qBACRD,OAAQ,OACRV,OAAQ,OACRwB,QAAS,OACTT,SAAU,WACVjB,gBAAiB,cACjBJ,MAAsB,UAAfd,EAAM6C,KAAmB,qBAAuB,wBACvD5B,QAAS,KAGb6B,MAAO7C,KAAKhB,MAAM8D,WAClBC,UAAQ,EACRC,IAAMC,IAAejD,KAAKjB,mBAAqBkE,KAEjD,8BACEtC,MACA,CACE4B,WAAW,QACXC,WAAWpC,EACXqC,UAAU,QACVC,WAAY,WACZZ,MAAQ,qBACRD,OAAQ,OACRV,OAAQ,OACRwB,QAAS,OACTT,SAAU,WACVjB,gBAAiB,cACjBJ,MAAMd,EAAMe,UACZE,QAAS,KAGX6B,MAAO7C,KAAKhB,MAAMkE,KAClBC,SAAUnD,KAAKmD,SACfC,UAAWpD,KAAKoD,UAChBf,OAAQrC,KAAKqD,gBACbC,SAAUtD,KAAKsD,SACfN,IAAMC,IAAejD,KAAKlB,aAAemE,QAKpD,KAQOK,SAAW,KACjBtD,KAAKuD,eACN,KACOJ,SAAYK,IAClB,MAAMN,EAAOM,EAAMC,OAAOZ,MAC1B7C,KAAK0D,SAAS,CAAER,OAAMJ,WAAY,KAGD,OAA7B9C,KAAKhB,MAAMa,eACb8D,OAAOC,aAAa5D,KAAKhB,MAAMa,eAIjC,MAAMgE,EAAQF,OAAOG,WAAW,KAC9B,GAAoB,KAAhBZ,EAAKa,OAAe,CACtB,MAAMC,EAAUhE,KAAKC,MAAME,KAAc,QACzCH,KAAKiE,QAAQf,EAAMc,GAASE,KAAKpB,IACA,KAA3B9C,KAAKhB,MAAMkE,KAAKa,QAClB/D,KAAK0D,SAAS,CAAEZ,WAAY9C,KAAKhB,MAAMkE,KAAOJ,QAInD,KAEH9C,KAAK0D,SAAS,CAAE7D,cAAegE,KAChC,KAGOT,UAAaI,IACH,QAAdA,EAAMW,MACRX,EAAMY,iBACNpE,KAAK0D,SAASW,IAAS,CACrBnB,KAAMmB,EAAUvB,WAChBA,WAAY,KACV,KAEF,MAAMwB,EAAiB,CACrBb,OAAQ,CAAEZ,MAAO7C,KAAKhB,MAAMkE,OAE9BlD,KAAKmD,SAASmB,OAGnB,KAESjB,gBAAkB,KACxBrD,KAAK0D,SAAS,CAAEa,mBAAmB,GAAS,KAC1CC,IAAUC,kBAAkBzE,KAAKhB,MAAMkE,MACvClD,KAAK0D,SAAS,CAAEZ,WAAY,QAE/B,KAEOV,SAAW,KACjBpC,KAAK0D,SAAS,CAAE3B,WAAW,KAC5B,KAEOO,QAAU,KAChBtC,KAAK0D,SAAS,CAAE3B,WAAW,KAC5B,KAEON,cAAgB,KACtBzB,KAAK0D,SAAS,CACZnE,cAAe,EACfC,mBAAoB,EACpBC,eAAgB,EAChBR,mBAAoB,EACpBS,UAAW,EACXC,WAAY,EACZC,UAAW,KAEd,KASO8E,gBAAkB,IAAIC,gBAAkB,KAGxCC,iBAAmBC,UACzB,MAAMC,EAAoB,GAE1B,IAAK,MAAMC,KAAYC,EAAW,CAAC,IAAD,IAChC,MAAMC,EAAgC,QAApB,EAAGF,EAASG,gBAAQ,aAAjB,EAAmBC,KAClChF,EAAOiF,KAAKC,OAAuB,QAAjB,EAAAN,EAASG,gBAAQ,aAAjB,EAAmBI,YAAa,MAIxD,GAFAC,QAAQC,IAAI,mBAAD,OAAoBP,EAAY,eAAe9E,GAErC,0BAAjB8E,EAA0C,CAE5C,MAAMQ,QAAmBzF,KAAK0F,YAAYT,EAAc9E,GAGlDwF,EAAcxF,EAAKyF,OAAS,gBAC5BC,EAAc,yBAAqBF,EAAW,gBAAQF,EAAU,4FAEtEX,EAAQgB,KAAKD,QAEbf,EAAQgB,KAAK,iBAAD,OAAkBb,IAIlC,OAAOH,GACR,KAGOY,YAAcb,MAAOkB,EAAkB5F,KAC7C,GAAiB,0BAAb4F,EAAsC,CAExC,IAAIH,EAAQ,GAEVA,EADwB,kBAAfzF,EAAKyF,MACNzF,EAAKyF,MACJzF,EAAKyF,OAA+B,kBAAfzF,EAAKyF,MAE3BzF,EAAKyF,MAAMI,YAAc,GAEzBC,OAAO9F,EAAKyF,OAAS,IAG/BL,QAAQC,IAAI,sBAAD,OAAuBI,EAAK,MAGvC,MAAMM,EAAiBlG,KAAKC,MAAME,KAAuB,iBACnDgG,EAAoBnG,KAAKC,MAAME,KAA0B,oBACzDiG,EAAepG,KAAKC,MAAME,KAAqB,eAErD,GAAI+F,GAAkBC,GAAqBC,EACzC,IAEE,MAAMC,QAA0BC,MAAM,uCAAwC,CAC5EC,OAAQ,OACRC,QAAS,CACP,cAAgB,UAAD,OAAYJ,GAC3B,eAAgB,oBAElBK,KAAMrB,KAAKsB,UAAU,CACnBC,MAAO3G,KAAKC,MAAME,KAAsB,iBAAK,yBAC7CyG,MAAOhB,MAIX,IAAKS,EAAkBQ,GACrB,MAAM,IAAIC,MAAM,qBAAD,OAAsBT,EAAkBU,SAGzD,MACMC,SADsBX,EAAkBY,QACTC,KAAK,GAAGC,UAIvCC,GADsBpH,KAAKC,MAAME,KAA2B,qBAC7CH,KAAKC,MAAME,KAAoB,eAAK,2BAGzD,IAAIkH,EAGFA,EAFED,EAAaE,SAAS,SAAWF,EAAaE,SAAS,gBAEjD,kBAAcF,EAAY,UAG1B,UAAMA,EAAY,oBAAYjB,EAAiB,UAGzDZ,QAAQC,IAAI,uBAAD,OAAwB6B,IAEnC,MAAME,QAAuBjB,MAAMe,EAAU,CAC3Cd,OAAQ,OACRC,QAAS,CACP,UAAWN,EACX,eAAgB,oBAElBO,KAAMrB,KAAKsB,UAAU,CACnBc,OAAQR,EACRS,KAAMzH,KAAKC,MAAME,KAAiB,YAAK,EACvCuH,iBAAiB,MAIrB,IAAKH,EAAeV,GAClB,MAAM,IAAIC,MAAM,uBAAD,OAAwBS,EAAeR,SAGxD,MAAMY,QAAmBJ,EAAeN,OAExC,GAAIU,EAAWC,SAAWD,EAAWC,QAAQC,OAAS,EAAG,CACvD,MAAM/C,EAAU6C,EAAWC,QACxBE,IAAKC,IAAU,eAAmB,QAAd,EAAAA,EAAMC,gBAAQ,aAAd,EAAgB9E,QAAsB,QAAlB,EAAI6E,EAAMC,gBAAQ,aAAd,EAAgBC,UAAW,eACvEC,OAAQhF,GAAuB,eAATA,GAEzB,GAAI4B,EAAQ+C,OAAS,EACnB,MAAM,SAAN,OAAgB/C,EAAQ+C,OAAM,+BAAuB/C,EAAQqD,KAAK,SAKtE,MAAO,GACP,MAAOC,GAEP,OADA7C,QAAQ6C,MAAM,yBAA0BA,GACjC,GAKX,MAAO,GAGT,MAAO,IACR,KAGOC,iBAAmBxD,MAAOyD,EAAgBC,EAAmBC,KACnE,MAAMC,EAAc,mCAA+BD,EAAYL,KAAK,MAAK,0BAAkBI,EAAS,KAE9F,EAA8GvI,KAAKC,MAAME,MAAzH,gBAACuI,EAAe,QAAEC,EAAO,OAAE9G,EAAM,WAAEW,EAAU,OAAErB,EAAQ+B,KAAM0F,EAAY,eAAEC,GAAgC,EAAbC,EAAY,iBAK1GC,GAJSL,EACZM,QAAQ,SAAUJ,GAAgB,IAClCI,QAAQ,mBAAoBH,GAAkB,IAGb,SAAlC7I,KAAKC,MAAME,KAAiB,YAC5BmI,EAAOhB,SAAS,sBAGlB,IAAI2B,EACJ,GAAIF,EAAW,CACb,MAAMG,EAAmB,GACrBJ,EAAanC,QAAOuC,EAAYvC,MAAQmC,EAAanC,OACrDmC,EAAaK,aAAYD,EAAYC,WAAaL,EAAaK,YAC/DL,EAAaM,cAAaF,EAAYE,YAAcN,EAAaM,aACjEN,EAAaO,QAAOH,EAAYG,MAAQP,EAAaO,OACrDP,EAAaQ,OAAMJ,EAAYI,KAAOR,EAAaQ,MAEvDL,EAAO,yBACLM,SAAU,CACR,CACEC,KAAM,OACNvB,QAASQ,KAGVS,GAAW,IACdO,QAAQ,SAGVR,EAAO,yBACLS,OAAQjB,GACLK,GAAY,IACfa,MAAM,IAIV,MAAMnD,EAAkC,CACtC,eAAgB,oBAGdmC,IACFnC,EAAuB,cAAC,iBAAamC,IAGvC,IACE,MAAMiB,QAAiBtD,MAAMgC,EAAQ,CACnC/B,OAAQ,OACRC,QAASA,EACTC,KAAMrB,KAAKsB,UAAUuC,GACrBY,OAAQ7J,KAAK0E,gBAAgBmF,SAG/B,IAAKD,EAAS/C,GACZ,MAAM,IAAIC,MAAM,uBAAD,OAAwB8C,EAAS7C,SAGlD,MAAM+C,QAAqBF,EAAS3C,OAEpC,IAAI8C,EAAe,GACnB,GAAIhB,GAAae,EAAaE,SAAWF,EAAaE,QAAQ,IAAMF,EAAaE,QAAQ,GAAGC,QAC1FF,EAAeD,EAAaE,QAAQ,GAAGC,QAAQhC,YAC1C,MAAI6B,EAAaE,SAAWF,EAAaE,QAAQ,IAAMF,EAAaE,QAAQ,GAAG9G,MAIpF,OADAqC,QAAQ6C,MAAM,8BAA+B0B,GACtC,GAHPC,EAAeD,EAAaE,QAAQ,GAAG9G,KAOzC,IAAIgH,EAAkB,GACtB,MAAMC,EAAiBJ,EAAaK,QAAQ,YAC5C,IAAwB,IAApBD,EAAuB,CACzBD,EAAkBH,EAAaM,UAAUF,EAAiB,GAC1D,MAAMG,EAAcJ,EAAgBE,QAAQ,cACvB,IAAjBE,IACFJ,EAAkBA,EAAgBG,UAAU,EAAGC,SAGjDJ,EAAkBH,EAGpB,OAAOG,EACP,MAAO9B,GAEP,OADA7C,QAAQ6C,MAAM,wBAAyBA,GAChC,KAEV,KAEKnE,QAAUY,MAAO3B,EAAcc,KAKrC,GAHAhE,KAAK0E,gBAAgB6F,QACrBvK,KAAK0E,gBAAkB,IAAIC,gBAEP,KAAhBzB,EAAKa,OACP,MAAO,GAGT,MAAM7E,EAAgBC,KAAKC,MAAMC,KAAKC,MAAQ,KAC9C,GAAIJ,EAAgBc,KAAKhB,MAAME,cAC7Bc,KAAK0D,SAAS,CACZxE,cAAeA,EACfD,mBAAoB,SAEjB,GAAIe,KAAKhB,MAAMC,mBAAqBe,KAAKC,MAAME,KAAgB,UAEpE,OAAO,IAAIqK,QAASC,IAClB3G,WAAW,KACT2G,EAAQzK,KAAKiE,QAAQf,EAAMc,KAC1B,OAIP,MAAM,EAAuHhE,KAAKC,MAAME,MAAlI,gBAACuI,EAAe,QAAEgC,EAAO,QAAE/B,EAAO,OAAE9G,EAAM,WAAEW,EAAU,OAAErB,EAAQ+B,KAAM0F,EAAY,eAAEC,GAAgC,EAAbC,EAAY,iBACnHY,EAAShB,EACZM,QAAQ,SAAUJ,GAAgB,IAClCI,QAAQ,mBAAoBH,GAAkB,IAK3CE,EAC8B,SAAlC/I,KAAKC,MAAME,KAAiB,YAC5B6D,EAAQsD,SAAS,qBAIbqD,EAAQ,CACZ,CACEC,KAAM,WACN1F,SAAU,CACRC,KAAM,wBACN0F,YAAa,kEACbC,WAAY,CACVF,KAAM,SACNG,WAAY,CACVnF,MAAO,CACLgF,KAAM,SACNC,YAAa,yDAGjBG,SAAU,CAAC,aAMnB,IAAI/B,EACJ,GAAIF,EAAW,CAEb,MAAMG,EAAmB,GACrBJ,EAAanC,QAAOuC,EAAYvC,MAAQmC,EAAanC,OACrDmC,EAAaK,aAAYD,EAAYC,WAAaL,EAAaK,YAC/DL,EAAaM,cAAaF,EAAYE,YAAcN,EAAaM,aACjEN,EAAaO,QAAOH,EAAYG,MAAQP,EAAaO,OACrDP,EAAaQ,OAAMJ,EAAYI,KAAOR,EAAaQ,MAEvDL,EAAO,yBACLM,SAAU,CACR,CACEC,KAAM,OACNvB,QAASyB,KAGVR,GAAW,IACdyB,MAAOA,EACPM,YAAa,OACbxB,QAAQ,SAIVR,EAAO,yBACLS,OAAQA,GACLZ,GAAY,IACfa,MAAM,IAIV,MAAMnD,EAAkC,CACtC,eAAgB,oBAIdmC,IACFnC,EAAuB,cAAC,iBAAamC,IAGvC,IAAK,IAAD,IAEF3I,KAAK0D,SAASW,IAAS,CACrB9E,cAAe8E,EAAU9E,cAAgB,KAG3C,MAAMqK,QAAiBtD,MAAMtC,EAAS,CACpCuC,OAAQ,OACRC,QAASA,EACTC,KAAMrB,KAAKsB,UAAUuC,GACrBY,OAAQ7J,KAAK0E,gBAAgBmF,SAG/B,IAAKD,EAAS/C,GAAI,CAChB,MAAMqE,QAAkBtB,EAAS1G,OAQjC,MAPAqC,QAAQ6C,MAAM,sBAAuB8C,GAGrClL,KAAK0D,SAASW,IAAS,CACrB5E,eAAgB4E,EAAU5E,eAAiB,KAGvC,IAAIqH,MAAM,uBAAD,OAAwB8C,EAAS7C,SAGlD/G,KAAK0D,SAASW,IAAS,CACrBpF,mBAAoBoF,EAAUpF,mBAAqB,EACnDO,mBAAoB6E,EAAU7E,mBAAqB,KAGrD,MAAMsK,QAAqBF,EAAS3C,OAG9BkE,GAAgC,QAAlB,EAAArB,EAAasB,aAAK,aAAlB,EAAoBC,gBAAiB,EACnDC,GAAiC,QAAlB,EAAAxB,EAAasB,aAAK,aAAlB,EAAoBG,oBAAqB,EAExDC,EAAaxL,KAAKC,MAAME,KAAiB,YAAK,IAC9CsL,EAAczL,KAAKC,MAAME,KAAwB,mBAAK,GAGtDuL,EAAuBP,GAAehM,KAAKwM,KAAKjC,EAAO7B,OAAS,GAGhE+D,EAAgBF,EAAuB,IAAaF,EACpDK,GAHwBP,GAAgB,GAGC,IAAaG,EAE5DzL,KAAK0D,SAASW,IAAS,CACrB3E,UAAW2E,EAAU3E,UAAYkM,EACjCjM,WAAY0E,EAAU1E,WAAakM,EACnCjM,UAAWyE,EAAUzE,UAAYgM,EAAeC,KAIlD,IAAI9B,EAAe,GACfE,EAAU,KAEd,GAAIlB,GAAae,EAAaE,SAAWF,EAAaE,QAAQ,IAAMF,EAAaE,QAAQ,GAAGC,QAC1FA,EAAUH,EAAaE,QAAQ,GAAGC,QAClCF,EAAeE,EAAQhC,SAAW,OAC7B,MAAI6B,EAAaE,SAAWF,EAAaE,QAAQ,IAAMF,EAAaE,QAAQ,GAAG9G,MAIpF,OADAqC,QAAQ6C,MAAM,8BAA+B0B,GACtC,GAHPC,EAAeD,EAAaE,QAAQ,GAAG9G,KAUzC,GAHAqC,QAAQC,IAAI,oBAAqBuE,GAG7BhB,GAAakB,GAAWA,EAAQ6B,YAAc7B,EAAQ6B,WAAWjE,OAAS,EAAG,CAC/EtC,QAAQC,IAAI,uBAAwByE,EAAQ6B,YAG5C,MAAMtD,QAAoBxI,KAAK4E,iBAAiBqF,EAAQ6B,YACxDvG,QAAQC,IAAI,0BAA2BgD,GAGvC,MAAMuD,QAAsB/L,KAAKqI,iBAAiBrE,EAASd,EAAMsF,GAGjE,IAAI0B,EAAkB,GACtB,MAAMC,EAAiB4B,EAAc3B,QAAQ,YAC7C,IAAwB,IAApBD,EAAuB,CACzBD,EAAkB6B,EAAc1B,UAAUF,EAAiB,GAC3D,MAAMG,EAAcJ,EAAgBE,QAAQ,cACvB,IAAjBE,IACFJ,EAAkBA,EAAgBG,UAAU,EAAGC,QAE5C,CAEL,MAAM0B,EAAgBD,EAAc3B,QAAQ,WAC5C,IAAuB,IAAnB4B,EAAsB,CACxB,MAAMC,EAAgBF,EAAc3B,QAAQ,YAG1CF,GAFqB,IAAnB+B,EAEgBF,EAAc1B,UAAU4B,EAAgB,GAAGlI,OAG3CgI,EAAc1B,UAAU2B,EAAgB,GAAGjI,YAI/DmG,EAAkB6B,EAQtB,OAHA7B,EAAkBA,EAAgBlB,QAAQ,4BAA6B,IAAIjF,OAE3EwB,QAAQC,IAAI,mCAAoC0E,GACzCA,EAIT,IAAIA,EAAkB,GACtB,MAAMC,EAAiBJ,EAAaK,QAAQ,YAC5C,IAAwB,IAApBD,EAAuB,CACzBD,EAAkBH,EAAaM,UAAUF,EAAiB,GAE1D,MAAMG,EAAcJ,EAAgBE,QAAQ,cACvB,IAAjBE,IACFJ,EAAkBA,EAAgBG,UAAU,EAAGC,SAIjDJ,EAAkBH,EAMpB,OAFAxE,QAAQC,IAAI,oBAAqB0E,GAE1BA,EACP,MAAO9B,GACP,OAAIA,aAAiBtB,OAAwB,eAAfsB,EAAMjD,MAGpCI,QAAQ6C,MAAM,0BAA2BA,GAFhC,KA9hBJ8D,qBACHlM,KAAKlB,cAAgBkB,KAAKjB,qBAC5BiB,KAAKjB,mBAAmBoN,UAAYnM,KAAKlB,aAAaqN,WA4ExDC,uBACmC,OAA7BpM,KAAKhB,MAAMa,eACb8D,OAAOC,aAAa5D,KAAKhB,MAAMa,gBAsdtBwM,kBAAwBzN,GCxsBvC0N,IAASxM,OACP,kBAAC,IAAMyM,WAAU,KACf,kBAAC,EAAc,OAEjBC,SAASC,eAAe,U","file":"static/js/main.47f308f7.chunk.js","sourcesContent":["import {\n  StreamlitComponentBase,\n  withStreamlitConnection,\n  Streamlit,\n} from \"streamlit-component-lib\"\nimport React, { ReactNode } from \"react\"\n\ninterface State {\n  text: string\n  suggestion: string\n  isFocused: boolean\n  textAreaIsFocused: boolean\n  requestsThisMinute: number\n  currentMinute: number\n  totalRequests: number\n  successfulRequests: number\n  failedRequests: number\n  inputCost: number\n  outputCost: number\n  totalCost: number\n  debounceTimer: number | null\n}\n\nclass Copilot extends StreamlitComponentBase<State> {\n\n  private userTextarea: HTMLTextAreaElement | null = null;\n  private suggestionTextarea: HTMLTextAreaElement | null = null;\n  public state = {\n    \"text\": \"\",\n    \"suggestion\": \"\",\n    \"isFocused\": false,\n    'textAreaIsFocused': false,\n    requestsThisMinute: 0,\n    currentMinute: Math.floor(Date.now() / 60000),\n    totalRequests: 0,\n    successfulRequests: 0,\n    failedRequests: 0,\n    inputCost: 0,\n    outputCost: 0,\n    totalCost: 0,\n    debounceTimer: null,\n  }\n\n  public render = (): ReactNode => {\n    const { theme } = this.props\n    if (!theme) {\n      return <div>Theme is undefined, please check streamlit version.</div>\n    }\n    const height_int = this.props.args[\"height\"]\n    const font_fam = theme.font;\n\n    const f_height = height_int + 'px';\n\n    const f_focused = '1px solid ' + theme.primaryColor;\n    const f_not_focused = '1px solid ' + theme.secondaryBackgroundColor;\n\n    return (\n        <div>\n          {/* Request Counter Display */}\n          <div style={{\n            fontSize: '1em',\n            color: theme.textColor,\n            marginBottom: '0.5em',\n            padding: '0.5em',\n            backgroundColor: theme.backgroundColor,\n            borderRadius: '0.3em',\n            border: '1px solid ' + theme.secondaryBackgroundColor,\n            display: 'flex',\n            justifyContent: 'space-between',\n            alignItems: 'center'\n          }}>\n            <div>\n               <strong>API Stats:</strong> Total: {this.state.totalRequests} | \n              ✅ Success: {this.state.successfulRequests} | \n              ❌ Failed: {this.state.failedRequests} | \n              {/* Shows how many API requests have been made in the current minute, out of the allowed requests per minute (RPM) limit */}\n              Requests this per minute / limit: {this.state.requestsThisMinute} / {this.props.args[\"rpm_limit\"]} \n              <br />\n              <strong>Cost:</strong> Input: ${this.state.inputCost.toFixed(6)} | Output: ${this.state.outputCost.toFixed(6)} | Total: ${this.state.totalCost.toFixed(6)}\n              \n              \n            </div>\n            <button\n              onClick={this.resetCounters}\n              style={{\n                fontSize: '0.7em',\n                padding: '0.2em 0.5em',\n                backgroundColor: theme.primaryColor,\n                color: 'white',\n                border: 'none',\n                borderRadius: '0.3em',\n                cursor: 'pointer'\n              }}\n              title=\"Reset counters\"\n            >\n              🔄 Reset\n            </button>\n          </div>\n          \n          <div\n            tabIndex={0}\n            style={\n              {\n                height:f_height,\n                width:'auto',\n                border:this.state.isFocused ? f_focused: f_not_focused,\n                borderRadius:'0.5em',\n                overflowY:'scroll',\n                overflowX:'hidden',\n                position: 'relative',\n                backgroundColor: theme.secondaryBackgroundColor\n              }\n            }\n            onFocus={this._onFocus}\n            onBlur={this._onBlur}\n          >\n            <textarea\n              style={\n                {\n                  marginLeft:'0.5em',\n                  fontFamily:font_fam,\n                  marginTop:'0.2em',\n                  whiteSpace: 'pre-wrap',\n                  width:  'calc(100% - 1.2em)',\n                  height: '100%',\n                  border: 'none',\n                  outline: 'none',\n                  position: 'absolute',\n                  backgroundColor: 'transparent',\n                  color: theme.base === 'light' ? 'rgba(41,51,62,0.5)' : 'rgba(255,255,255,0.5)',\n                  padding: '0'\n                }\n              }\n              value={this.state.suggestion}\n              readOnly\n              ref={(textarea) => { this.suggestionTextarea = textarea; }}\n            />\n            <textarea\n              style={\n              {\n                marginLeft:'0.5em',\n                fontFamily:font_fam,\n                marginTop:'0.2em',\n                whiteSpace: 'pre-wrap',\n                width:  'calc(100% - 1.2em)',\n                height: '100%',\n                border: 'none',\n                outline: 'none',\n                position: 'absolute',\n                backgroundColor: 'transparent',\n                color:theme.textColor,\n                padding: '0'\n              }\n            }\n              value={this.state.text}\n              onChange={this.onChange}\n              onKeyDown={this.onKeyDown}\n              onBlur={this._onTextAreaBlur}\n              onScroll={this.onScroll}\n              ref={(textarea) => { this.userTextarea = textarea; }}\n            />\n          </div>\n        </div>\n    )\n  }\n\n  public componentDidUpdate(): void {\n  if (this.userTextarea && this.suggestionTextarea) {\n    this.suggestionTextarea.scrollTop = this.userTextarea.scrollTop;\n  }\n}\n\n  private onScroll = (): void => {\n    this.forceUpdate();\n  }\n  private onChange = (event: React.ChangeEvent<HTMLTextAreaElement>): void => {\n    const text = event.target.value\n    this.setState({ text, suggestion: \"\" })\n    \n    // Clear any existing timer\n    if (this.state.debounceTimer !== null) {\n      window.clearTimeout(this.state.debounceTimer!)\n    }\n    \n    // Set a new debounced timer (500ms delay)\n    const timer = window.setTimeout(() => {\n      if (text.trim() !== \"\") {\n        const api_upl = this.props.args[\"api_url\"]\n        this.callApi(text, api_upl).then(suggestion => {\n          if (this.state.text.trim() !== \"\") {\n            this.setState({ suggestion: this.state.text + suggestion })\n          }\n        })\n      }\n    }, 500) // Wait 500ms after user stops typing\n    \n    this.setState({ debounceTimer: timer })\n  }\n\n\n  private onKeyDown = (event: React.KeyboardEvent<HTMLTextAreaElement>): void => {\n  if (event.key === 'Tab') {\n    event.preventDefault()\n    this.setState(prevState => ({\n      text: prevState.suggestion,\n      suggestion: ''\n    }), () => {\n      // Create a synthetic event and call onChange manually\n      const syntheticEvent = {\n        target: { value: this.state.text }\n      } as React.ChangeEvent<HTMLTextAreaElement>;\n      this.onChange(syntheticEvent);\n    })\n  }\n}\n\n  private _onTextAreaBlur = (): void => {\n    this.setState({ textAreaIsFocused: false }, () => {\n      Streamlit.setComponentValue(this.state.text);\n      this.setState({ suggestion: '' });\n    });\n  }\n\n  private _onFocus = (): void => {\n    this.setState({ isFocused: true })\n  }\n\n  private _onBlur = (): void => {\n    this.setState({ isFocused: false })\n  }\n\n  private resetCounters = (): void => {\n    this.setState({\n      totalRequests: 0,\n      successfulRequests: 0,\n      failedRequests: 0,\n      requestsThisMinute: 0,\n      inputCost: 0,\n      outputCost: 0,\n      totalCost: 0\n    });\n  }\n\n  // Cleanup timer when component unmounts\n  componentWillUnmount(): void {\n    if (this.state.debounceTimer !== null) {\n      window.clearTimeout(this.state.debounceTimer!)\n    }\n  }\n\n  private abortController = new AbortController();\n\n  // Add tool call execution method\n  private executeToolCalls = async (toolCalls: any[]): Promise<string[]> => {\n    const results: string[] = [];\n    \n    for (const toolCall of toolCalls) {\n      const functionName = toolCall.function?.name;\n      const args = JSON.parse(toolCall.function?.arguments || '{}');\n      \n      console.log(`Executing tool: ${functionName} with args:`, args);\n      \n      if (functionName === 'search_knowledge_base') {\n        // Execute the real Pinecone search tool with enhanced source info\n        const toolResult = await this.executeTool(functionName, args);\n        \n        // Add source context to the result\n        const searchQuery = args.query || 'unknown query';\n        const enhancedResult = `Search Query: \"${searchQuery}\"\\n\\n${toolResult}\\n\\nSource: Information retrieved from Lysa's knowledge base via Pinecone vector search.`;\n        \n        results.push(enhancedResult);\n      } else {\n        results.push(`Unknown tool: ${functionName}`);\n      }\n    }\n    \n    return results;\n  }\n\n  // Real Pinecone search tool results\n  private executeTool = async (toolName: string, args: any): Promise<string> => {\n    if (toolName === 'search_knowledge_base') {\n      // Extract query string safely\n      let query = '';\n      if (typeof args.query === 'string') {\n        query = args.query;\n      } else if (args.query && typeof args.query === 'object') {\n        // If query is an object, try to get the value\n        query = args.query.toString() || '';\n      } else {\n        query = String(args.query || '');\n      }\n      \n      console.log(`Processing query: \"${query}\"`);\n      \n      // Use real Pinecone search if credentials are available\n      const pineconeApiKey = this.props.args[\"pinecone_api_key\"];\n      const pineconeIndexName = this.props.args[\"pinecone_index_name\"];\n      const openaiApiKey = this.props.args[\"openai_api_key\"];\n      \n      if (pineconeApiKey && pineconeIndexName && openaiApiKey) {\n        try {\n          // Generate embedding using OpenAI REST API\n          const embeddingResponse = await fetch('https://api.openai.com/v1/embeddings', {\n            method: 'POST',\n            headers: {\n              'Authorization': `Bearer ${openaiApiKey}`,\n              'Content-Type': 'application/json'\n            },\n            body: JSON.stringify({\n              model: this.props.args[\"embedding_model\"] || \"text-embedding-ada-002\",\n              input: query\n            })\n          });\n          \n          if (!embeddingResponse.ok) {\n            throw new Error(`OpenAI API error: ${embeddingResponse.status}`);\n          }\n          \n          const embeddingData = await embeddingResponse.json();\n          const queryEmbedding = embeddingData.data[0].embedding;\n          \n          // Search Pinecone using REST API\n          const pineconeEnvironment = this.props.args[\"pinecone_environment\"];\n          const pineconeHost = this.props.args[\"pinecone_host\"] || \"https://api.pinecone.io\";\n          \n          // Construct the correct Pinecone query endpoint\n          let indexUrl;\n          if (pineconeHost.includes('svc.') && pineconeHost.includes('.pinecone.io')) {\n            // If pinecone_host already contains the full index URL, use it directly\n            indexUrl = `https://${pineconeHost}/query`;\n          } else {\n            // Otherwise, construct the standard Pinecone API URL\n            indexUrl = `${pineconeHost}/indexes/${pineconeIndexName}/query`;\n          }\n          \n          console.log(`Pinecone query URL: ${indexUrl}`);\n          \n          const searchResponse = await fetch(indexUrl, {\n            method: 'POST',\n            headers: {\n              'Api-Key': pineconeApiKey,\n              'Content-Type': 'application/json'\n            },\n            body: JSON.stringify({\n              vector: queryEmbedding,\n              topK: this.props.args[\"search_top\"] || 3,\n              includeMetadata: true\n            })\n          });\n          \n          if (!searchResponse.ok) {\n            throw new Error(`Pinecone API error: ${searchResponse.status}`);\n          }\n          \n          const searchData = await searchResponse.json();\n          \n          if (searchData.matches && searchData.matches.length > 0) {\n            const results = searchData.matches\n              .map((match: any) => match.metadata?.text || match.metadata?.content || 'No content')\n              .filter((text: any) => text !== 'No content');\n            \n            if (results.length > 0) {\n              return `Found ${results.length} relevant results:\\n${results.join('\\n\\n')}`;\n            }\n          }\n          \n          // No results found\n          return \"\";\n        } catch (error) {\n          console.error(\"Pinecone search error:\", error);\n          return \"\";\n        }\n      }\n      \n      // No credentials available\n      return \"\";\n    }\n    \n    return \"\";\n  }\n\n  // Add follow-up call method for tool results\n  private makeFollowUpCall = async (apiUrl: string, userInput: string, toolResults: string[]): Promise<string> => {\n    const followUpPrompt = `Based on search results: ${toolResults.join('\\n')}\\n\\nComplete: \"${userInput}\"`;\n    \n    const {prompt_template, api_key, height, fontFamily, border, text: questionText, question_title, ...model_kwargs} = this.props.args;\n    const prompt = prompt_template\n      .replace(\"{text}\", questionText || \"\")\n      .replace(\"{question_title}\", question_title || \"\");\n    \n    const isChatApi = (\n      this.props.args[\"api_format\"] === \"chat\" ||\n      apiUrl.includes('/chat/completions')\n    );\n\n    let payload;\n    if (isChatApi) {\n      const validParams: any = {};\n      if (model_kwargs.model) validParams.model = model_kwargs.model;\n      if (model_kwargs.max_tokens) validParams.max_tokens = model_kwargs.max_tokens;\n      if (model_kwargs.temperature) validParams.temperature = model_kwargs.temperature;\n      if (model_kwargs.top_p) validParams.top_p = model_kwargs.top_p;\n      if (model_kwargs.stop) validParams.stop = model_kwargs.stop;\n\n      payload = {\n        messages: [\n          {\n            role: \"user\",\n            content: followUpPrompt\n          }\n        ],\n        ...validParams,\n        stream: false\n      };\n    } else {\n      payload = {\n        prompt: followUpPrompt,\n        ...model_kwargs,\n        echo: false\n      };\n    }\n    \n    const headers: Record<string, string> = {\n      'Content-Type': 'application/json'\n    };\n    \n    if (api_key) {\n      headers['Authorization'] = `Bearer ${api_key}`;\n    }\n\n    try {\n      const response = await fetch(apiUrl, {\n        method: \"POST\",\n        headers: headers,\n        body: JSON.stringify(payload),\n        signal: this.abortController.signal\n      });\n\n      if (!response.ok) {\n        throw new Error(`HTTP error! status: ${response.status}`);\n      }\n\n      const responseJson = await response.json();\n      \n      let fullResponse = \"\";\n      if (isChatApi && responseJson.choices && responseJson.choices[0] && responseJson.choices[0].message) {\n        fullResponse = responseJson.choices[0].message.content;\n      } else if (responseJson.choices && responseJson.choices[0] && responseJson.choices[0].text) {\n        fullResponse = responseJson.choices[0].text;\n      } else {\n        console.error(\"Unexpected response format:\", responseJson);\n        return \"\";\n      }\n      \n      // Extract answer from response\n      let extractedAnswer = \"\";\n      const answerTagIndex = fullResponse.indexOf(\"<answer>\");\n      if (answerTagIndex !== -1) {\n        extractedAnswer = fullResponse.substring(answerTagIndex + 8);\n        const endTagIndex = extractedAnswer.indexOf(\"</answer>\");\n        if (endTagIndex !== -1) {\n          extractedAnswer = extractedAnswer.substring(0, endTagIndex);\n        }\n      } else {\n        extractedAnswer = fullResponse;\n      }\n      \n      return extractedAnswer;\n    } catch (error) {\n      console.error(\"Follow-up call error:\", error);\n      return \"\";\n    }\n  }\n\nprivate callApi = async (text: string, api_upl: string): Promise<string> => {\n  // Abort the previous request\n  this.abortController.abort();\n  this.abortController = new AbortController();\n\n  if (text.trim() === \"\") {\n    return \"\";\n  }\n\n  const currentMinute = Math.floor(Date.now() / 60000);\n  if (currentMinute > this.state.currentMinute) {\n    this.setState({\n      currentMinute: currentMinute,\n      requestsThisMinute: 0\n    });\n  } else if (this.state.requestsThisMinute > this.props.args[\"rpm_limit\"]) {\n    // Retry after 1 second if limit is exceeded\n    return new Promise((resolve) => {\n      setTimeout(() => {\n        resolve(this.callApi(text, api_upl));\n      }, 1000);\n    });\n  }\n\n  const {prompt_template, api_url, api_key, height, fontFamily, border, text: questionText, question_title, ...model_kwargs} = this.props.args;\n  const prompt = prompt_template\n    .replace(\"{text}\", questionText || \"\")\n    .replace(\"{question_title}\", question_title || \"\"); // format the prompt with both placeholders\n  \n  // Generalize to support both chat and legacy completions APIs, not just Groq\n  // Determine if the API expects chat format (messages) or legacy format (prompt)\n  // Use a prop or model_kwargs to allow user to specify the format, fallback to auto-detect\n  const isChatApi = (\n    this.props.args[\"api_format\"] === \"chat\" ||\n    api_upl.includes('/chat/completions')\n  );\n\n  // Definiera verktyg för API-anropet\n  const tools = [\n    {\n      type: \"function\",\n      function: {\n        name: \"search_knowledge_base\",\n        description: \"Sök i Lysas kunskapsbas efter information för kundsupport\",\n        parameters: {\n          type: \"object\",\n          properties: {\n            query: {\n              type: \"string\",\n              description: \"Sökfråga för att hitta relevant information\"\n            }\n          },\n          required: [\"query\"]\n        }\n      }\n    }\n  ];\n\n  let payload;\n  if (isChatApi) {\n    // Use chat completions format for any compatible API\n    const validParams: any = {};\n    if (model_kwargs.model) validParams.model = model_kwargs.model;\n    if (model_kwargs.max_tokens) validParams.max_tokens = model_kwargs.max_tokens;\n    if (model_kwargs.temperature) validParams.temperature = model_kwargs.temperature;\n    if (model_kwargs.top_p) validParams.top_p = model_kwargs.top_p;\n    if (model_kwargs.stop) validParams.stop = model_kwargs.stop;\n\n    payload = {\n      messages: [\n        {\n          role: \"user\",\n          content: prompt\n        }\n      ],\n      ...validParams,\n      tools: tools,\n      tool_choice: \"auto\",\n      stream: false\n    };\n  } else {\n    // Use legacy completions format for other APIs\n    payload = {\n      prompt: prompt,\n      ...model_kwargs,\n      echo: false\n    };\n  }\n  \n  const headers: Record<string, string> = {\n    'Content-Type': 'application/json'\n  };\n  \n  // Add API key if provided\n  if (api_key) {\n    headers['Authorization'] = `Bearer ${api_key}`;\n  }\n\n  try {\n    // Increment total requests counter\n    this.setState(prevState => ({\n      totalRequests: prevState.totalRequests + 1\n    }));\n    \n    const response = await fetch(api_upl, {\n      method: \"POST\",\n      headers: headers,\n      body: JSON.stringify(payload),\n      signal: this.abortController.signal\n    });\n\n    if (!response.ok) {\n      const errorText = await response.text();\n      console.error(\"API Error Response:\", errorText);\n      \n      // Increment failed requests counter\n      this.setState(prevState => ({\n        failedRequests: prevState.failedRequests + 1\n      }));\n      \n      throw new Error(`HTTP error! status: ${response.status}`);\n    }\n\n    this.setState(prevState => ({\n      requestsThisMinute: prevState.requestsThisMinute + 1,\n      successfulRequests: prevState.successfulRequests + 1\n    }));\n\n    const responseJson = await response.json();\n    \n    // Calculate costs based on token usage\n    const inputTokens = responseJson.usage?.prompt_tokens || 0;\n    const outputTokens = responseJson.usage?.completion_tokens || 0;\n    \n    const inputPrice = this.props.args[\"token_cost\"] || 0.05;\n    const outputPrice = this.props.args[\"output_token_cost\"] || 0.10;\n    \n    // If no usage info, estimate based on text length (rough approximation)\n    const estimatedInputTokens = inputTokens || Math.ceil(prompt.length / 4);\n    const estimatedOutputTokens = outputTokens || 0;\n    \n    const newInputCost = (estimatedInputTokens / 1_000_000) * inputPrice;\n    const newOutputCost = (estimatedOutputTokens / 1_000_000) * outputPrice;\n    \n    this.setState(prevState => ({\n      inputCost: prevState.inputCost + newInputCost,\n      outputCost: prevState.outputCost + newOutputCost,\n      totalCost: prevState.totalCost + newInputCost + newOutputCost\n    }));\n    \n    // Handle both chat completions and legacy completions formats\n    let fullResponse = \"\";\n    let message = null;\n    \n    if (isChatApi && responseJson.choices && responseJson.choices[0] && responseJson.choices[0].message) {\n      message = responseJson.choices[0].message;\n      fullResponse = message.content || \"\";\n    } else if (responseJson.choices && responseJson.choices[0] && responseJson.choices[0].text) {\n      fullResponse = responseJson.choices[0].text;\n    } else {\n      console.error(\"Unexpected response format:\", responseJson);\n      return \"\";\n    }\n    \n    // Log the full response to console (this will show the thinking process)\n    console.log(\"Full AI Response:\", fullResponse);\n    \n    // Check if there are tool calls\n    if (isChatApi && message && message.tool_calls && message.tool_calls.length > 0) {\n      console.log(\"Tool calls detected:\", message.tool_calls);\n      \n      // Execute the tool calls\n      const toolResults = await this.executeToolCalls(message.tool_calls);\n      console.log(\"Tool execution results:\", toolResults);\n      \n      // Make a follow-up call with the tool results\n      const finalResponse = await this.makeFollowUpCall(api_upl, text, toolResults);\n      \n      // Extract answer from the follow-up response\n      let extractedAnswer = \"\";\n      const answerTagIndex = finalResponse.indexOf(\"<answer>\");\n      if (answerTagIndex !== -1) {\n        extractedAnswer = finalResponse.substring(answerTagIndex + 8);\n        const endTagIndex = extractedAnswer.indexOf(\"</answer>\");\n        if (endTagIndex !== -1) {\n          extractedAnswer = extractedAnswer.substring(0, endTagIndex);\n        }\n      } else {\n        // If no <answer> tags, try to find content after <think> tags or return clean response\n        const thinkTagIndex = finalResponse.indexOf(\"<think>\");\n        if (thinkTagIndex !== -1) {\n          const endThinkIndex = finalResponse.indexOf(\"</think>\");\n          if (endThinkIndex !== -1) {\n            // Extract content after </think> tag\n            extractedAnswer = finalResponse.substring(endThinkIndex + 8).trim();\n          } else {\n            // No closing </think> tag, take everything after <think>\n            extractedAnswer = finalResponse.substring(thinkTagIndex + 7).trim();\n          }\n        } else {\n          // No tags found, return the full response\n          extractedAnswer = finalResponse;\n        }\n      }\n      \n      // Clean up the extracted answer\n      extractedAnswer = extractedAnswer.replace(/<think>[\\s\\S]*?<\\/think>/g, '').trim();\n      \n      console.log(\"Extracted Answer from follow-up:\", extractedAnswer);\n      return extractedAnswer;\n    }\n    \n    // Extract only the content after <answer> tag\n    let extractedAnswer = \"\";\n    const answerTagIndex = fullResponse.indexOf(\"<answer>\");\n    if (answerTagIndex !== -1) {\n      extractedAnswer = fullResponse.substring(answerTagIndex + 8); // 8 is the length of \"<answer>\"\n      // Remove any trailing tags or extra content\n      const endTagIndex = extractedAnswer.indexOf(\"</answer>\");\n      if (endTagIndex !== -1) {\n        extractedAnswer = extractedAnswer.substring(0, endTagIndex);\n      }\n    } else {\n      // If no <answer> tag found, return the full response\n      extractedAnswer = fullResponse;\n    }\n    \n    // Log the extracted answer for debugging\n    console.log(\"Extracted Answer:\", extractedAnswer);\n    \n    return extractedAnswer;\n  } catch (error) {\n    if (error instanceof Error && error.name === 'AbortError') {\n      return \"\";  // Return empty string if request was aborted\n    }\n    console.error(\"Error decoding response\", error);\n    return \"\";\n  }\n}\n}\n\nexport default withStreamlitConnection(Copilot)\n","import React from \"react\"\nimport ReactDOM from \"react-dom\"\nimport ScrollableText from \"./streamlit_copilot\"\n\nReactDOM.render(\n  <React.StrictMode>\n    <ScrollableText />\n  </React.StrictMode>,\n  document.getElementById(\"root\")\n)\n"],"sourceRoot":""}